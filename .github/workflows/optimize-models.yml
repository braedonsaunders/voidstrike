name: Optimize 3D Models

on:
  workflow_dispatch:  # Manual trigger only

jobs:
  optimize:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Optimize models
        run: |
          echo "ðŸŽ® Installing gltf-transform..."
          npm install -g @gltf-transform/cli

          # Clean up any extracted texture/bin files from previous bad runs
          echo "ðŸ§¹ Cleaning up extracted files..."
          find public/models -name "*.webp" -type f -delete 2>/dev/null || true
          find public/models -name "*.bin" -type f -delete 2>/dev/null || true

          echo "ðŸ“¦ Optimizing models..."
          files=$(find public/models -name "*.glb" -type f)

          for file in $files; do
            echo "Processing: $file"
            dir=$(dirname "$file")
            base=$(basename "$file")
            # Use temp filename with .glb extension so gltf-transform outputs GLB format
            temp_file="optimized_${base}"

            # Get original size
            original_size=$(stat -c%s "$file")
            echo "  Original size: $((original_size / 1024)) KB"

            # Change to file directory to avoid path issues with gltf-transform
            pushd "$dir" > /dev/null

            # Apply Draco compression - output must end in .glb to stay as binary GLB
            echo "  Applying Draco compression..."
            gltf-transform draco "$base" "$temp_file" || {
              echo "  âš ï¸ Draco compression failed, keeping original"
              popd > /dev/null
              continue
            }

            # Debug: show what files exist
            echo "  Files after draco:"
            ls -la *.glb* 2>/dev/null || true

            # Check if optimized file exists and has reasonable size
            if [ -f "$temp_file" ]; then
              opt_size=$(stat -c%s "$temp_file")
              echo "  Optimized file size: $((opt_size / 1024)) KB"

              # Only replace if optimized file is > 1MB (sanity check for these large models)
              if [ $opt_size -gt 1048576 ]; then
                mv "$temp_file" "$base"
                echo "  âœ… Replaced with optimized version"
              else
                echo "  âš ï¸ Optimized file too small ($((opt_size / 1024)) KB), keeping original"
                rm -f "$temp_file"
              fi
            else
              echo "  âš ï¸ Optimized file not found, keeping original"
            fi

            # Clean up any extracted .bin files
            rm -f *.bin 2>/dev/null || true

            popd > /dev/null

            # Get final size
            new_size=$(stat -c%s "$file")
            if [ $original_size -gt 0 ]; then
              reduction=$((100 - (new_size * 100 / original_size)))
              echo "  Final size: $((new_size / 1024)) KB (${reduction}% reduction)"
            fi
          done

      - name: Commit optimized models
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

          # Final cleanup of any extracted files
          find public/models -name "*.webp" -type f -delete 2>/dev/null || true
          find public/models -name "*.bin" -type f -delete 2>/dev/null || true

          # Only add GLB files (not extracted textures)
          git add public/models/**/*.glb

          # Check if there are changes to commit
          if git diff --staged --quiet; then
            echo "No changes to commit (models may already be optimized)"
          else
            git commit -m "chore: Optimize 3D models (Draco compression)"
            git push
          fi
